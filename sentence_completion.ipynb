{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cd268d6",
   "metadata": {},
   "source": [
    "# Natural Language Processing\n",
    "## A Sentence Completion ML Model\n",
    "- The first part of this project is a sentence completion model that takes in 5 words as independent features, and predicts what the following word would be. It is to help user typing more efficient by learning typing patterns from the user's conversation history.\n",
    "\n",
    "- The second part is to then use the model within a function that iteratively uses the model to predict the 5th word of a pattern, by layering the sentence each time a prediction is made, to continually predict a long array of words based on the specified limit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd7e7e2",
   "metadata": {},
   "source": [
    "Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8ea1557",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0162326",
   "metadata": {},
   "source": [
    "Opening the text file and representing it by a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d824bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Video Games.txt\", \"r\", encoding=\"utf-8\") as text_file:\n",
    "    initial_text = text_file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee65723",
   "metadata": {},
   "source": [
    "Remove all punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dabe67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&’*_~'''\n",
    "punctuations = r'''!()-[]{};:'\"\\,<>./?@#$%^&’*_~'''\n",
    "# Remove punctuations from the text\n",
    "text_variable = ''.join(char for char in initial_text if char not in punctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20415068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(text_variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc921bb3",
   "metadata": {},
   "source": [
    "This stage first tokenizes the whole `Video Games.txt` file and then, creates the dataset needed to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "865e78c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input: ['video', 'games', 'have', 'evolved', 'into']\n",
      "Target word: a\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the text\n",
    "tokens = word_tokenize(text_variable.lower())\n",
    "\n",
    "#stop words\n",
    "# stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Remove stopwords\n",
    "# filtered_tokens = [token for token in tokens if token.isalpha() and token not in stop_words]\n",
    "\n",
    "# Create dataset: 5-word sequences with 6th word as target\n",
    "input_sequences = []\n",
    "target_words = []\n",
    "\n",
    "for i in range(len(tokens) - 5):\n",
    "    input_sequences.append(tokens[i:i+5])\n",
    "    target_words.append(tokens[i+5])\n",
    "\n",
    "# Preview\n",
    "print(\"Sample input:\", input_sequences[0])\n",
    "print(\"Target word:\", target_words[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450f0eb3",
   "metadata": {},
   "source": [
    "This stage then joins the word token in each row to form a king of sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f878d7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "the_list = []\n",
    "\n",
    "for words in input_sequences:\n",
    "    new_clean_text = ' '.join(words)\n",
    "\n",
    "    the_list.append(new_clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19b0cef",
   "metadata": {},
   "source": [
    "This creates the final dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49beec96",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_df = pd.DataFrame({'Sentence' : the_list, 'Target' : target_words})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76e84752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>video games have evolved into</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>games have evolved into a</td>\n",
       "      <td>major</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>have evolved into a major</td>\n",
       "      <td>form</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>evolved into a major form</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>into a major form of</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12607</th>\n",
       "      <td>high score because in the</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12608</th>\n",
       "      <td>score because in the world</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12609</th>\n",
       "      <td>because in the world of</td>\n",
       "      <td>games</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12610</th>\n",
       "      <td>in the world of games</td>\n",
       "      <td>anythings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12611</th>\n",
       "      <td>the world of games anythings</td>\n",
       "      <td>possible</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12612 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Sentence         Target\n",
       "0      video games have evolved into              a\n",
       "1          games have evolved into a          major\n",
       "2          have evolved into a major           form\n",
       "3          evolved into a major form             of\n",
       "4               into a major form of  entertainment\n",
       "...                              ...            ...\n",
       "12607      high score because in the          world\n",
       "12608     score because in the world             of\n",
       "12609        because in the world of          games\n",
       "12610          in the world of games      anythings\n",
       "12611   the world of games anythings       possible\n",
       "\n",
       "[12612 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e22589e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "and            420\n",
       "the            362\n",
       "a              329\n",
       "of             263\n",
       "to             234\n",
       "              ... \n",
       "wasnt            1\n",
       "cultivation      1\n",
       "formed           1\n",
       "chat             1\n",
       "anythings        1\n",
       "Name: Target, Length: 3613, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df.Target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e00163cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus_df.Target = corpus_df.Target.apply(lambda x :'others' if x not in corpus_top else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "215f0304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "and            420\n",
       "the            362\n",
       "a              329\n",
       "of             263\n",
       "to             234\n",
       "              ... \n",
       "wasnt            1\n",
       "cultivation      1\n",
       "formed           1\n",
       "chat             1\n",
       "anythings        1\n",
       "Name: Target, Length: 3613, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df.Target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936df560",
   "metadata": {},
   "source": [
    "This converts each sentence into a vector of numbers usin the `TF-IDF` encoding technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b8534c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(corpus_df.Sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c525f4",
   "metadata": {},
   "source": [
    "This displayes the vectors in the from of `(doc_index, feature_index)    tfidf_score` instead of a sparce matrix for memory efficiency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26875e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1676)\t0.36304682846865993\n",
      "  (0, 1098)\t0.6368387560404972\n",
      "  (0, 1458)\t0.46580932310381934\n",
      "  (0, 1320)\t0.2876209140440805\n",
      "  (0, 3391)\t0.4036449968197907\n",
      "  (1, 1676)\t0.3968090537138697\n",
      "  (1, 1098)\t0.6960627785089225\n",
      "  (1, 1458)\t0.5091281405530329\n",
      "  (1, 1320)\t0.31436876397338415\n",
      "  (2, 1873)\t0.5433142907210021\n",
      "  (2, 1676)\t0.35092439516401003\n",
      "  (2, 1098)\t0.6155741842537654\n",
      "  (2, 1458)\t0.4502555652709021\n",
      "  (3, 1265)\t0.5309563308389728\n",
      "  (3, 1873)\t0.515627982573967\n",
      "  (3, 1676)\t0.3330419262012861\n",
      "  (3, 1098)\t0.5842056433490291\n",
      "  (4, 2134)\t0.27857704997764005\n",
      "  (4, 1265)\t0.6283073780335314\n",
      "  (4, 1873)\t0.6101685712266656\n",
      "  (4, 1676)\t0.3941052912885008\n",
      "  (5, 1055)\t0.4806625003031631\n",
      "  (5, 2134)\t0.26579808489588636\n",
      "  (5, 1265)\t0.599485484610713\n",
      "  (5, 1873)\t0.5821787462704642\n",
      "  :\t:\n",
      "  (12607, 2727)\t0.552879490168834\n",
      "  (12607, 263)\t0.4339450374497415\n",
      "  (12607, 1492)\t0.6050552565970259\n",
      "  (12607, 3145)\t0.2347879970344969\n",
      "  (12607, 1601)\t0.2912021750197425\n",
      "  (12608, 2727)\t0.6106197010003567\n",
      "  (12608, 263)\t0.47926427680873757\n",
      "  (12608, 3517)\t0.4762069231486692\n",
      "  (12608, 3145)\t0.2593081839659075\n",
      "  (12608, 1601)\t0.3216140012481008\n",
      "  (12609, 263)\t0.5692578852136301\n",
      "  (12609, 3517)\t0.565626438508548\n",
      "  (12609, 3145)\t0.30799964772239474\n",
      "  (12609, 1601)\t0.3820049084915437\n",
      "  (12609, 2134)\t0.3394416872947241\n",
      "  (12610, 3517)\t0.6243701047167574\n",
      "  (12610, 3145)\t0.3399872410636084\n",
      "  (12610, 1601)\t0.42167838785275585\n",
      "  (12610, 2134)\t0.374694723252822\n",
      "  (12610, 1320)\t0.41995458068025987\n",
      "  (12611, 148)\t0.7754777442859581\n",
      "  (12611, 3517)\t0.4347544374541347\n",
      "  (12611, 3145)\t0.23673612912207917\n",
      "  (12611, 2134)\t0.26090325656881386\n",
      "  (12611, 1320)\t0.2924180964153604\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e1fac97",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = corpus_df.Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "36966382",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f77d000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_model = RandomForestClassifier()\n",
    "RF_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b27bd507",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_y_pred = RF_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b10e1283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02915754210359439\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print(f1_score(y_test, rf_y_pred, average= 'weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b8a106",
   "metadata": {},
   "source": [
    "Model Fuitting using the `Multinomial Naive Bayes` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81ed8677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_model = MultinomialNB()\n",
    "NB_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "269f9a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_y_pred = NB_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9d40ec95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.011500818522530043\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_test, nb_y_pred, average= 'weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c31a08",
   "metadata": {},
   "source": [
    "## Why we did not measure performance by evaluation metrics\n",
    "We realized that evaluation metrics will not be adequate in trying to access how well the model performs because of how varied the target column is. The target column is just every 6th word of a layered version of the text. After splitting the data, the train set and test set will not harbor the same pattern, that we can use to try to evaluate correctness. It is just random, and works based on how the text was fed into the model.  \n",
    "The team decided to point this out by trying to compare F1 scores of our two models. This was done for completeness sake.  \n",
    "\n",
    "The true measure of performance is by checking how well the model can predict a suitable next word."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2454172c",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3378f1a",
   "metadata": {},
   "source": [
    "The code below simply predicts the next word based on the input text and the model you want to apply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c6aa81f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_word(input, model):\n",
    "    input_df = pd.Series(str(input))\n",
    "\n",
    "    # Transform the input text using the same vectorizer\n",
    "    new_review = vectorizer.transform(input_df)\n",
    "\n",
    "    # Get class output\n",
    "    output = model.predict(new_review)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4256e47",
   "metadata": {},
   "source": [
    "This function does the following:\n",
    "- takes the user's input orignially stored as `new-review` and the converts it into a Pandas series whiich the Vectorizer can then work with.\n",
    "- transforms the input text into a vector of numbers using the `TF-IDF` vectorizer.\n",
    "- gets the probabilities of all possible targets from the `NB` model.\n",
    "- sorts all the target probabilities, sorts them and picks the top 5.\n",
    "- randomly picks one out of the top 5 predictions (to introduce a sense of variability).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cfc53f",
   "metadata": {},
   "source": [
    "Using the same phrase, we passed it into both models to see what they would likely pass as a next word prediction, to try to check for which one of them gives a next word with a better meaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c231869b",
   "metadata": {},
   "source": [
    "### User input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2b79f0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_review = input(\"Enter text here:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87299e2c",
   "metadata": {},
   "source": [
    "### Check User input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "39ef20f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "games video good before make\n"
     ]
    }
   ],
   "source": [
    "print(new_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70039ac0",
   "metadata": {},
   "source": [
    "### Random Forest model result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5249fbd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['are']\n"
     ]
    }
   ],
   "source": [
    "print(predict_word(new_review, RF_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cecf551",
   "metadata": {},
   "source": [
    "### Naive Bayes model result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9fd282ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a']\n"
     ]
    }
   ],
   "source": [
    "print(predict_word(new_review, NB_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40972157",
   "metadata": {},
   "source": [
    "The function below is a new version of the \"predict word\" function that we will use for continuous generation of words in order to form a long compilation of texts. It takes in both the user's input and the model of choice and this time, tries to get the top 5 words that match the selection of words given by the user, based on probability. From there, it'll pick a random choice from these top 5 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d5b7d6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_word(input, model):\n",
    "    input_df = pd.Series(str(input))\n",
    "\n",
    "    # Transform the input text using the same vectorizer\n",
    "    new_review = vectorizer.transform(input_df)\n",
    "    # Get class probabilities\n",
    "    proba = model.predict_proba(new_review)\n",
    "\n",
    "    # Get top 5 classes for each sample\n",
    "    top_k = 5\n",
    "    top_classes = np.argsort(proba, axis=1)[:, -top_k:][:, ::-1]  # sort and reverse\n",
    "\n",
    "    # Map to class labels\n",
    "    top_class_labels = model.classes_[top_classes][0]\n",
    "    rand_variable = random.choice(top_class_labels)\n",
    "\n",
    "    return rand_variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803c9b45",
   "metadata": {},
   "source": [
    "This generates a sentence based on the given input and model of choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d186d2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(words, model):\n",
    "    count = 50  # number of words to generate\n",
    "    word_list = words.split(\" \")  # turn input into list of words\n",
    "\n",
    "    for n in range(count):\n",
    "        main_words = ' '.join(word_list)  # form the current context string\n",
    "        next_word = str(predict_word(main_words, model))  # predict the next word\n",
    "        words = words + \" \" + next_word  # add it to the sentence\n",
    "        word_list = word_list[1:]  # shift the context window\n",
    "        word_list.append(next_word)  # include the new word\n",
    "\n",
    "    return words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49b3d9c",
   "metadata": {},
   "source": [
    "The code above simply generates a 30 word sentence based on the input text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a8bd476a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "games video good before make fewer games kind of your poetry into controller making a feel like like rather video a exceed games entertainment entertainment and in isnt therapy nothing of playing—its belonging in bonkers video exceed games just entertainment entertainment industries to education and for from the pixelated seeing pride decorating of and arcade\n"
     ]
    }
   ],
   "source": [
    "print(generate_sentence(new_review, RF_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "55c4da32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "games video good before make of and a the gaming the the a and a of a in and of a of the gaming to to of to and of to to and of the the of and a the of and of and gaming of and and and the the the a of of\n"
     ]
    }
   ],
   "source": [
    "print(generate_sentence(new_review, NB_model))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bb19be",
   "metadata": {},
   "source": [
    "## Performance check\n",
    "This shows that the Random forest model actually performs betters in terms of spewing more suitable words. It shows that the Naive Bayes model gives mostly worlds that fall under the category of \"Stopwords\". Perhaps this is due to the fact that Naive Bayes models put more importance on how much of occurrence of the word, that is why the NB model tended to spew out more stopwords, because stopwords appear the most in the dataset(text)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
